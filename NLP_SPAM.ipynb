{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "# NLP (Natural language processing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1: Key Concepts, text data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "from collections import Counter\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.wordnet import WordNetLemmatizer \n",
    "from nltk.stem import SnowballStemmer\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer \n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline  import Pipeline, FeatureUnion, make_pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import nltk\n",
    "import math\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "corpus = [\"Jack stole my tuna sandwich.\", \n",
    "    \"'Help!' I sobbed, sandwichlessly.\", \n",
    "    \"'Drop the sandwiches!' said the sandwich police.\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Function for tokenize °||° Corpus -> list of documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def our_tokenizer(doc, stops=None, stemmer=None):\n",
    "    doc = word_tokenize(doc.lower())\n",
    "    tokens = [''.join([char for char in tok if char not in string.punctuation]) for tok in doc]\n",
    "    tokens = [tok for tok in tokens if tok]\n",
    "    if stops:\n",
    "        tokens = [tok for tok in tokens if (tok not in stops)]\n",
    "    if stemmer:\n",
    "        tokens = [stemmer.stem(tok) for tok in tokens]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "creating a list of token lists, where each internal list represents the tokens of a document in the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['jack', 'stole', 'my', 'tuna', 'sandwich'],\n",
       " ['help', 'i', 'sobbed', 'sandwichlessly'],\n",
       " ['drop', 'the', 'sandwiches', 'said', 'the', 'sandwich', 'police']]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_docs = [our_tokenizer(doc) for doc in corpus]\n",
    "tokenized_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Step 1: lowercase, lose punctuation, split into tokens\n",
    "```\n",
    "# 'i' in stopwords\n",
    "  is True \n",
    "\n",
    "  because \n",
    "    ∴  \n",
    "Row: ['jack', 'stole', 'my', 'tuna', 'sandwich'], Conteo de 'i': 1\n",
    "Row: ['help', 'i', 'sobbed', 'sandwichlessly'], Conteo de 'i': 2\n",
    "Row: ['drop', 'the', 'sandwiches', 'said', 'the', 'sandwich', 'police'],4 Counting  'i': 7\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-------+\n",
      "| tokenized_docs   |   i   |\n",
      "+==================+=======+\n",
      "| Row  1           |     1 |\n",
      "+------------------+-------+\n",
      "| Row  2           |     2 |\n",
      "+------------------+-------+\n",
      "| Row  3           |     4 |\n",
      "+------------------+-------+\n",
      "| Total     ∴'i'∴  |     7 |\n",
      "+------------------+-------+\n"
     ]
    }
   ],
   "source": [
    "# validate the occurrences of \"i\" in all sublists\n",
    "\n",
    "def contar_i(lista):\n",
    "    return sum(words.lower().count('i') for words in lista)\n",
    "\n",
    "table_data = []\n",
    "for i, renglon in enumerate(tokenized_docs, start=1):\n",
    "    count_i = contar_i(renglon)\n",
    "    table_data.append([f'Row  {i}'      , count_i])\n",
    "\n",
    "total_i_in_all_lists = sum(count for _, count in table_data)\n",
    "table_data.append([\"Total     ∴'i'∴\", total_i_in_all_lists])\n",
    "print(tabulate(table_data, headers=[\"tokenized_docs\", \"i  \"], tablefmt=\"grid\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['jack', 'stole', 'tuna', 'sandwich'],\n",
       " ['help', 'sobbed', 'sandwichlessly'],\n",
       " ['drop', 'sandwiches', 'said', 'sandwich', 'police']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter out tokenized words and exclude those that are stopwords.\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "corpus = list(corpus)\n",
    "\n",
    "# Get the stopwords in English\n",
    "stopwords_english = set(stopwords.words('english'))\n",
    "\n",
    "# Then apply tokenization and stopword filtering\n",
    "tokenized_docs = [our_tokenizer(doc, stops=stopwords_english) for doc in corpus]\n",
    "\n",
    "tokenized_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Step 2: remove stop words\n",
    "```\n",
    "[\n",
    " ['jack', 'stole', 'tuna', 'sandwich'],\n",
    " ['help', 'sobbed', 'sandwichlessly'],\n",
    " ['drop', 'sandwiches', 'said', 'sandwich', 'police']\n",
    "]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['jack', 'stole', 'tuna', 'sandwich'],\n",
       " ['help', 'sob', 'sandwichless'],\n",
       " ['drop', 'sandwich', 'said', 'sandwich', 'polic']]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stemming process of reducing words to their root or base, which often \n",
    "# involves removing suffixes and prefixes.\n",
    "tokenized_docs = [our_tokenizer(doc, stops=stopwords.words('english'), stemmer=SnowballStemmer('english')) for doc in corpus]\n",
    "tokenized_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Step 3: Stemming/Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Vocabulary:\n",
    "```\n",
    "['drop', 'help', 'jack', 'tuna', 'police', 'said', 'sandwich', 'sandwichlessly', 'sobbed', 'stole']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['jack', 'drop', 'polic', 'sandwich', 'tuna', 'sob', 'sandwichless', 'said', 'help', 'stole']\n"
     ]
    }
   ],
   "source": [
    "# It is initialized as an empty set that way vocab_set will be\n",
    "# ready to store unique elements without duplicates\n",
    "vocabulary = list(set(word for doc in tokenized_docs for word in doc))\n",
    "print(vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2: Count Vectorizer, TFIDF "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In the given list, the words that have a term frequency (TF) value of zero are those that do not appear in the document. In the first document ['jack', 'stole', 'sandwich', 'tuna'], the words \"jack\" and \"stole\" have a term frequency value of zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.         0.08115802]\n",
      " [0.         1.         0.        ]\n",
      " [0.08115802 0.         1.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Calculates and returns the term frequency of each word \n",
    "# in the vocabulary for the provided document.\n",
    "def cal_tf(document, vocabulary):\n",
    "    tf_vector = []\n",
    "    total_words = len(document)\n",
    "    for words in vocabulary:\n",
    "        tf = document.count(words) / total_words\n",
    "        tf_vector.append(tf)\n",
    "    return tf_vector\n",
    "\n",
    "\n",
    "#Calculates and returns the document frequency of each word\n",
    "# in the vocabulary across the provided set of tokenized documents\n",
    "def cal_df(tokenized_docs, vocabulary):\n",
    "    df_vector = []\n",
    "    total_tokenized_docs = len(tokenized_docs)\n",
    "    for words in vocabulary:\n",
    "        df = sum(1 for doc in tokenized_docs if words in doc) / total_tokenized_docs\n",
    "        df_vector.append(df)\n",
    "    return df_vector\n",
    "\n",
    "\n",
    "#It returns a list of IDF values, where each value\n",
    "# represents the importance of a term in the context of \n",
    "# the entire document collection.\n",
    "def calc_idf(df_vector):\n",
    "    idf_vector = [math.log(1 / df) if df != 0 else 0 for df in df_vector]\n",
    "    return idf_vector\n",
    "\n",
    "\n",
    "#The function computes the TF-IDF values for a document\n",
    "# by multiplying the term frequency (TF) values by the inverse \n",
    "# document frequency (IDF) values for each term. The result is a \n",
    "# list of TF-IDF values representing the importance of each term in \n",
    "# the document relative to the entire collection of documents.\n",
    "def cal_tfidf(tf_vector, idf_vector):\n",
    "    return [tf * idf for tf, idf in zip(tf_vector, idf_vector)]\n",
    "\n",
    "tf_vectors = [cal_tf(doc, vocabulary) for doc in tokenized_docs]\n",
    "df_vector = cal_df(tokenized_docs, vocabulary)\n",
    "idf_vector = calc_idf(df_vector)\n",
    "tfidf_vectors = [list(map(lambda x: round(x, 3), cal_tfidf(tf, idf_vector))) for tf in tf_vectors]\n",
    "\n",
    "similarities = cosine_similarity(tfidf_vectors)\n",
    "print(similarities)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Vector 0 is very similar to itself (similarity 1.).\n",
    "Vector 0 is not very similar to vector 1 (similarity 0.).\n",
    "Vector 0 is not very similar to vector 2 (similarity 0.08115802).\n",
    "Vector 1 is very similar to itself (similarity 1.).\n",
    "Vector 1 is not very similar to vector 0 (similarity 0.).\n",
    "Vector 1 is not very similar to vector 2 (similarity 0.).\n",
    "Vector 2 is very similar to itself (similarity 1.).\n",
    "Vector 2 is not very similar to vector 0 (similarity 0.08115802).\n",
    "Vector 2 is very similar to vector 1 (similarity 0.).\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3: Example with Spam data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0                                                  1\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.read_table(r'SMSSpamCollection', header=None)\n",
    "df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spam</th>\n",
       "      <th>msg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   spam                                                msg\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns=['spam', 'msg']\n",
    "df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Filter      |   Quantity\n",
      "-------------+------------\n",
      " Stopwords   |        179\n",
      " Punctuation |         32\n"
     ]
    }
   ],
   "source": [
    "#The following code removes prepositions and punctuation marks \n",
    "# or characters from the original text.\n",
    "stopwords_set = set(stopwords.words('english'))\n",
    "punctuation_set = set(string.punctuation)\n",
    "data = [['Stopwords', len(stopwords_set)], ['Punctuation', len(punctuation_set)]]\n",
    "print(tabulate(data, headers=['Filter', 'Quantity'], tablefmt='presto'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spam</th>\n",
       "      <th>msg</th>\n",
       "      <th>msg_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>go jurong point, crazy.. available bugis n gre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>ok lar... joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>free entry 2 wkly comp win fa cup final tkts 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>u dun say early hor... u c already say...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   spam                                                msg  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...   \n",
       "1   ham                      Ok lar... Joking wif u oni...   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3   ham  U dun say so early hor... U c already then say...   \n",
       "\n",
       "                                         msg_cleaned  \n",
       "0  go jurong point, crazy.. available bugis n gre...  \n",
       "1                      ok lar... joking wif u oni...  \n",
       "2  free entry 2 wkly comp win fa cup final tkts 2...  \n",
       "3          u dun say early hor... u c already say...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We create the column 'msg_ cleaned' in lowercase\n",
    "df['msg_cleaned'] = df['msg'].apply(lambda x: ' '.join([word.lower() for word in x.split() if word.lower() not in stopwords_set and word.lower() not in punctuation_set]))\n",
    "df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array     rows  | tokens\n",
      "-------  -----------------\n",
      "X.shape  (5572, 8693)\n"
     ]
    }
   ],
   "source": [
    "# Create a CountVectorizer object for transforms the text data \n",
    "# in the msg_ cleaned column of the DataFrame df into an array \n",
    "# of term counts\n",
    "count_vect= CountVectorizer()\n",
    "X= count_vect.fit_transform(df.msg_cleaned)\n",
    "print(tabulate([['X.shape', X.shape]], headers=['Array', ' rows  | tokens'], tablefmt='simple'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          rows\n",
      "------  ------\n",
      "Length    5572\n"
     ]
    }
   ],
   "source": [
    "y=df.spam\n",
    "y_info = [['', 'rows'],\n",
    "          ['Length', len(y)]]\n",
    "print(tabulate(y_info, headers='firstrow', tablefmt='simple'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+----------+\n",
      "|    |   % test |    Score |\n",
      "+====+==========+==========+\n",
      "|  1 |       20 | 0.984753 |\n",
      "+----+----------+----------+\n",
      "|  3 |       40 | 0.984747 |\n",
      "+----+----------+----------+\n",
      "|  0 |       10 | 0.983871 |\n",
      "+----+----------+----------+\n",
      "|  2 |       30 | 0.983852 |\n",
      "+----+----------+----------+\n",
      "|  4 |       50 | 0.981335 |\n",
      "+----+----------+----------+\n",
      "|  5 |       60 | 0.978768 |\n",
      "+----+----------+----------+\n",
      "|  6 |       70 | 0.974109 |\n",
      "+----+----------+----------+\n",
      "|  7 |       80 | 0.969493 |\n",
      "+----+----------+----------+\n",
      "|  8 |       90 | 0.956929 |\n",
      "+----+----------+----------+\n"
     ]
    }
   ],
   "source": [
    "# Iterate from 10% to 90% in 10% increments\n",
    "def calcular_scores(X, y):\n",
    "    resultados = []\n",
    "    for porcentaje in range(10, 91, 10):  \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=porcentaje/100, random_state=42)\n",
    "        lg = LogisticRegression()\n",
    "        lg.fit(X_train, y_train)\n",
    "        score = lg.score(X_test, y_test)\n",
    "        resultados.append({'% test': porcentaje, 'Score': score})\n",
    "    return pd.DataFrame(resultados)\n",
    "\n",
    "resultados = calcular_scores(X, y)\n",
    "resultados = resultados.sort_values(by='Score', ascending=False)\n",
    "print(tabulate(resultados, headers='keys', tablefmt='grid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We use 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[478,   1],\n",
       "       [ 11,  68]], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_train, X_test, y_train, y_test= train_test_split(X,y)    #By default it uses 25% \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n",
    "lg= LogisticRegression()\n",
    "lg.fit(X_train,y_train)\n",
    "y_pred=lg.predict(X_test)\n",
    "lg.score(X_test,y_test)\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+\n",
      "| Type               |   Quantity |\n",
      "+====================+============+\n",
      "| correct prediction |        546 |\n",
      "+--------------------+------------+\n",
      "| wrong prediction   |         12 |\n",
      "+--------------------+------------+\n"
     ]
    }
   ],
   "source": [
    "# number of correct and incorrect predictions\n",
    "print(tabulate([[\"correct prediction\", sum(y_test == y_pred)],[\"wrong prediction\",len(y_test) - sum(y_test == y_pred)]], headers=[\"Type\", \"Quantity\"], tablefmt=\"grid\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 4: Tweak model with Spam data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spam</th>\n",
       "      <th>msg</th>\n",
       "      <th>msg_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>go jurong point, crazy.. available bugis n gre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>ok lar... joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>free entry 2 wkly comp win fa cup final tkts 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>u dun say early hor... u c already say...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   spam                                                msg  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...   \n",
       "1   ham                      Ok lar... Joking wif u oni...   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3   ham  U dun say so early hor... U c already then say...   \n",
       "\n",
       "                                         msg_cleaned  \n",
       "0  go jurong point, crazy.. available bugis n gre...  \n",
       "1                      ok lar... joking wif u oni...  \n",
       "2  free entry 2 wkly comp win fa cup final tkts 2...  \n",
       "3          u dun say early hor... u c already say...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1215,    0],\n",
       "       [  28,  150]], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf= TfidfVectorizer()  \n",
    "X= tfidf.fit_transform(df.msg_cleaned)\n",
    "y=df.spam \n",
    "X_train, X_test, y_train, y_test= train_test_split(X,y)  \n",
    "## try random forest \n",
    "rf= RandomForestClassifier()\n",
    "rf.fit(X_train,y_train)\n",
    "y_pred=rf.predict(X_test)\n",
    "rf.score(X_test,y_test)\n",
    "confusion_matrix(y_test, y_pred)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1215,    1],\n",
       "       [  60,  117]], dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf=TfidfVectorizer()\n",
    "X=tfidf.fit_transform(df.msg_cleaned)\n",
    "y=df.spam\n",
    "X_train, X_test, y_train, y_test=  train_test_split(X,y)\n",
    "## try Logistic Regression\n",
    "lg= LogisticRegression()\n",
    "lg.fit(X_train,y_train)\n",
    "y_pred=lg.predict(X_test)\n",
    "lg.score(X_test,y_test)\n",
    "confusion_matrix(y_test, y_pred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1210,    1],\n",
       "       [ 125,   57]], dtype=int64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try tfidf with bigrams & trigrams \n",
    "tfidf=TfidfVectorizer(ngram_range=(1,3)) \n",
    "X= tfidf.fit_transform(df.msg_cleaned)\n",
    "y=df.spam\n",
    "X_train, X_test, y_train, y_test= train_test_split(X,y)\n",
    "## try Logistic Regression\n",
    "lg= LogisticRegression()\n",
    "lg.fit(X_train,y_train)\n",
    "y_pred=lg.predict(X_test)\n",
    "lg.score(X_test,y_test)\n",
    "confusion_matrix(y_test, y_pred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1201,    0],\n",
       "       [  43,  149]], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try tfidf with bigrams & trigrams \n",
    "tfidf=TfidfVectorizer(ngram_range=(1,3)) \n",
    "X= tfidf.fit_transform(df.msg_cleaned)\n",
    "y=df.spam\n",
    "X_train, X_test, y_train, y_test= train_test_split(X,y)\n",
    "## try Random Forest\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1197,    4],\n",
       "       [  40,  152]], dtype=int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#try gradient boost \n",
    "gb= GradientBoostingClassifier()\n",
    "gb.fit(X_train,y_train)\n",
    "y_pred=gb.predict(X_test)\n",
    "gb.score(X_test,y_test)\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5.5: Pipeline with Spam data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9755922469490309\n",
      "[[1183    3]\n",
      " [  31  176]]\n"
     ]
    }
   ],
   "source": [
    "# Define el conjunto de stopwords y conviértelo en una lista\n",
    "stopwords_set = set(stopwords.words('english'))\n",
    "stopwords_list = list(stopwords_set)\n",
    "pipeline= Pipeline([('countvect', CountVectorizer(stop_words=stopwords_list)),\\\n",
    "                    #('tfidf', TfidfVectorizer(stop_words=stopwords_set)),\\\n",
    "                    ('lg',  LogisticRegression())])\n",
    "\n",
    "X=df.msg_cleaned #note we are passing the cleaned msg to the pipeline \n",
    "y=df.spam\n",
    "X_train, X_test, y_train, y_test= train_test_split(X,y) \n",
    "\n",
    "pipeline.fit(X_train, y_train) \n",
    "y_pred= pipeline.predict(X_test)\n",
    "print (pipeline.score(X_test, y_test))\n",
    "print (confusion_matrix(y_test, y_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9885139985642498\n",
      "[[1214    4]\n",
      " [  12  163]]\n"
     ]
    }
   ],
   "source": [
    "# Define el conjunto de stopwords\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "clf = MultinomialNB()\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vectorizer', vectorizer),\n",
    "    ('clf', clf)\n",
    "])\n",
    "\n",
    "X=df.msg_cleaned \n",
    "y=df.spam\n",
    "X_train, X_test, y_train, y_test= train_test_split(X,y) \n",
    "\n",
    "pipeline.fit(X_train, y_train) \n",
    "y_pred= pipeline.predict(X_test)\n",
    "print (pipeline.score(X_test, y_test))\n",
    "print (confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this is with MultinomialNB classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9849246231155779\n",
      "[[1175   10]\n",
      " [  11  197]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "clf = MultinomialNB()\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vectorizer', vectorizer),\n",
    "    ('clf', clf)\n",
    "])\n",
    "\n",
    "X=df.msg_cleaned \n",
    "y=df.spam\n",
    "X_train, X_test, y_train, y_test= train_test_split(X,y) \n",
    "\n",
    "pipeline.fit(X_train, y_train) \n",
    "y_pred= pipeline.predict(X_test)\n",
    "print (pipeline.score(X_test, y_test))\n",
    "print (confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9806173725771715\n",
      "[[1214    1]\n",
      " [  26  152]]\n"
     ]
    }
   ],
   "source": [
    "stopwords_set = set(stopwords.words('english'))\n",
    "stopwords_list = list(stopwords_set)\n",
    "pipeline= Pipeline([#('countvect', CountVectorizer(stop_words=stopwords_set)),\\\n",
    "                    ('countvect', CountVectorizer(stop_words=stopwords_list)),\\\n",
    "                    ('rf',  RandomForestClassifier())])\n",
    "X=df.msg_cleaned #note we are passing the cleaned msg to the pipeline \n",
    "y=df.spam\n",
    "X_train, X_test, y_train, y_test= train_test_split(X,y) \n",
    "\n",
    "\n",
    "pipeline.fit(X_train, y_train) \n",
    "y_pred= pipeline.predict(X_test)\n",
    "print (pipeline.score(X_test, y_test))\n",
    "print (confusion_matrix(y_test, y_pred))  \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9691313711414213\n",
      "[[1206    0]\n",
      " [  43  144]]\n"
     ]
    }
   ],
   "source": [
    "stopwords_set = set(stopwords.words('english'))\n",
    "stopwords_list = list(stopwords_set)\n",
    "pipeline= Pipeline([#('countvect', CountVectorizer(stop_words=stopwords_set)),\\\n",
    "                    ('countvect', CountVectorizer(stop_words=stopwords_list, ngram_range=(1,3))),\\\n",
    "                    ('rf',  RandomForestClassifier())])\n",
    "X=df.msg_cleaned #note we are passing the cleaned msg to the pipeline \n",
    "y=df.spam\n",
    "X_train, X_test, y_train, y_test= train_test_split(X,y) \n",
    "\n",
    "\n",
    "pipeline.fit(X_train, y_train) \n",
    "y_pred= pipeline.predict(X_test)\n",
    "print (pipeline.score(X_test, y_test))\n",
    "print (confusion_matrix(y_test, y_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better hyperparameters: {'countvect__ngram_range': (1, 1), 'rf__max_depth': None, 'rf__n_estimators': 200}\n",
      "Accuracy of the best model: 0.9813352476669059\n",
      "Best model confusion matrix:\n",
      "[[1205    1]\n",
      " [  25  162]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "stopwords_set = set(stopwords.words('english'))\n",
    "stopwords_list = list(stopwords_set)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('countvect', CountVectorizer(stop_words=stopwords_list, ngram_range=(1,3))),\n",
    "    ('rf', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'countvect__ngram_range': [(1, 1), (1, 2), (1, 3)],  # N-gram range adjustment\n",
    "    'rf__n_estimators': [50, 100, 200],  # Adjusting the number of estimators in the RandomForestClassifier\n",
    "    'rf__max_depth': [None, 10, 20]  # Setting the maximum depth of the RandomForestClassifier\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "\n",
    "print(\"Better hyperparameters:\", best_params)\n",
    "print(\"Accuracy of the best model:\", best_model.score(X_test, y_test))\n",
    "print(\"Best model confusion matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_best))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9655419956927495\n",
      "[[1194    2]\n",
      " [  46  151]]\n"
     ]
    }
   ],
   "source": [
    "stopwords_set = set(stopwords.words('english'))\n",
    "stopwords_list = list(stopwords_set)\n",
    "pipeline= Pipeline([#('countvect', CountVectorizer(stop_words=stopwords_list)),\\\n",
    "                    ('tfidf', TfidfVectorizer(stop_words=stopwords_list)),\\\n",
    "                    ('lg',  LogisticRegression())])\n",
    "X=df.msg_cleaned #note we are passing the cleaned msg to the pipeline \n",
    "y=df.spam\n",
    "X_train, X_test, y_train, y_test= train_test_split(X,y) \n",
    "\n",
    "\n",
    "pipeline.fit(X_train, y_train) \n",
    "y_pred= pipeline.predict(X_test)\n",
    "print (pipeline.score(X_test, y_test))\n",
    "print (confusion_matrix(y_test, y_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better hyperparameters: {'lg__C': 10.0}\n",
      "Accuracy of the best model: 0.9813352476669059\n",
      "Best model confusion matrix:\n",
      "[[1196    2]\n",
      " [  24  171]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "stopwords_set = set(stopwords.words('english'))\n",
    "stopwords_list = list(stopwords_set)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(stop_words=stopwords_list)),\n",
    "    ('lg', LogisticRegression())\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'lg__C': [0.1, 1.0, 10.0]  # Example of adjusting the regularization parameter C in logistic regression\n",
    "}\n",
    "\n",
    "X = df.msg_cleaned\n",
    "y = df.spam\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "\n",
    "print(\"Better hyperparameters:\", best_params)\n",
    "print(\"Accuracy of the best model:\", best_model.score(X_test, y_test))\n",
    "print(\"Best model confusion matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_best))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9669777458722182\n",
      "[[1207    0]\n",
      " [  46  140]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "tfidf = TfidfTransformer()\n",
    "clf = MultinomialNB()\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vectorizer', vectorizer),\n",
    "    ('tfidf', tfidf),\n",
    "    ('clf', clf)\n",
    "])\n",
    "\n",
    "X=df.msg_cleaned \n",
    "y=df.spam\n",
    "X_train, X_test, y_train, y_test= train_test_split(X,y) \n",
    "\n",
    "pipeline.fit(X_train, y_train) \n",
    "y_pred= pipeline.predict(X_test)\n",
    "print (pipeline.score(X_test, y_test))\n",
    "print (confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better hyperparameters: {'clf__alpha': 0.1}\n",
      "Accuracy of the best model: 0.9813352476669059\n",
      "Best model confusion matrix:\n",
      "[[1204    3]\n",
      " [  23  163]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the hyperparameter grid to explore\n",
    "param_grid = {\n",
    "    'clf__alpha': [0.1, 0.5, 1.0]  # Example of tuning the alpha parameter of the Naive Bayes classifier\n",
    "}\n",
    "\n",
    "# Create a GridSearchCV object\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5)\n",
    "\n",
    "# Adjust the GridSearchCV object\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters and the best model\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions with the best model\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "\n",
    "# Print the precision and confusion matrix of the best model\n",
    "print(\"Better hyperparameters:\", best_params)\n",
    "print(\"Accuracy of the best model:\", best_model.score(X_test, y_test))\n",
    "print(\"Best model confusion matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_best))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['best_model.pkl']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "#Save the best model\n",
    "joblib.dump(best_model, 'best_model.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------+--------------+\n",
      "| Phrase                                         | Prediction   |\n",
      "+================================================+==============+\n",
      "| Example text 1                                 | ham          |\n",
      "+------------------------------------------------+--------------+\n",
      "| Example text  2                                | ham          |\n",
      "+------------------------------------------------+--------------+\n",
      "| Quarterly Sales Summary                        | ham          |\n",
      "+------------------------------------------------+--------------+\n",
      "| ¡Special offer! Win an amazing prize today!!!. | spam         |\n",
      "+------------------------------------------------+--------------+\n",
      "| Receive your $1000 check today!                | spam         |\n",
      "+------------------------------------------------+--------------+\n",
      "| Buy now and receive a 50% discount!            | spam         |\n",
      "+------------------------------------------------+--------------+\n",
      "| Your inheritance is waiting, contact us!       | ham          |\n",
      "+------------------------------------------------+--------------+\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Load the saved model\n",
    "loaded_model = joblib.load('best_model.pkl')\n",
    "\n",
    "#Make predictions on new data\n",
    "new_data = [\"Example text 1\", \"Example text  2\",'Quarterly Sales Summary',\"¡Special offer! Win an amazing prize today!!!.\",\"Receive your $1000 check today!\",'Buy now and receive a 50% discount!',' Your inheritance is waiting, contact us!']\n",
    "predictions = loaded_model.predict(new_data)\n",
    "\n",
    "# Create a list of tuples (phrase, prediction)\n",
    "results = list(zip(new_data, predictions))\n",
    "\n",
    "# Print results with tabulate\n",
    "print(tabulate(results, headers=[\"Phrase\", \"Prediction\"], tablefmt=\"grid\"))\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "livereveal": {
   "transition": "none"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
